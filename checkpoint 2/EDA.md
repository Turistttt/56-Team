## После проведения разведочного анализа данных (EDA) для нашего проекта в основе которого лежит RAG (Retrieval-Augmented Generation), можно сделать следующие выводы:
## 1) Качество данных:
Пропущенные значения: Обнаружено небольшое количество пропущенных значений в столбце источник, в количестве 3 штук, которые в перспективе скорее всего придется просто удалить, так как оценить качество ответа на вопрос, которого нет - явно невозможно.
## 2) Распределение длины текста:
Большинство текстов имеют длину от 200 до 1400 токенов,что явно превышает окно контекста нашего эмбедера. Это может вполне отразиться на качестве retrieval-части проекта, поэтому в будущем есть смысл провести эксперименты с моделями имеющими большую длину контекста.
## 3) Визуализация:
Для визуализации данных были построены облака точек для контекста,вопросов и ответов.Так же был построен график наиболее встречаемых слов в questions, answers, context,и
построена визуализация эмбеддингов с помощью метода t-SNE.
## Более подробно про Гистограммы токенизированных questions, context, answer:
## Гистограмма контекстов
Видно, что тексты будут сильно обрубаться токенизатором, что в последствии может сказаться на точность RAG.
## Гистограмма Вопросов
Из гистограммы видно,что вопросы спокойно будут эмбеддится base-line моделью. Тут должно быть все хорошо
## Гистограмма Ответов:
Ответы так же спокойно будут эмбеддится base-line моделью. Тут должно так же должно быть все хорошо.
## Вывод:
Учитывая гистограмму контекстов ,вероятно придется использовать эмбедеры с большим окном контекста, или уже нарезать имеющиеся чанки на более мелкие части
