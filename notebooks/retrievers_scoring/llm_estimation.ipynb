{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0d2cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001-9df3a936e1f63191.parquet', 'test': 'data/test-00000-of-00001-af2a9f454ad1b8a3.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/neural-bridge/rag-dataset-12000/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b274e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caption: Tasmanian berry grower Nic Hansen sho...</td>\n",
       "      <td>What is the Berry Export Summary 2028 and what...</td>\n",
       "      <td>The Berry Export Summary 2028 is a dedicated e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RWSN Collaborations\\nSouthern Africa Self-supp...</td>\n",
       "      <td>What are some of the benefits reported from ha...</td>\n",
       "      <td>Benefits reported from having access to Self-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All Android applications categories\\nDescripti...</td>\n",
       "      <td>What are the unique features of the Coolands f...</td>\n",
       "      <td>The unique features of the Coolands for Twitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How unequal is India? The question is simple, ...</td>\n",
       "      <td>What is the main difference between the Nation...</td>\n",
       "      <td>The main difference between the NSS and the IH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gunnar Nelson took his time on the feet agains...</td>\n",
       "      <td>How did Gunnar Nelson win the fight against Za...</td>\n",
       "      <td>Gunnar Nelson won the fight against Zak Cummin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>For teenagers, getting their first car is a ri...</td>\n",
       "      <td>What are some ways to lower the cost of a teen...</td>\n",
       "      <td>Some ways to lower the cost of a teenager's ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9596</th>\n",
       "      <td>I Sold the Farm (farm #1) for a client in cent...</td>\n",
       "      <td>What was the unique action taken by the buyer ...</td>\n",
       "      <td>The buyer took the brand new sign of the selle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9597</th>\n",
       "      <td>Entry 150, during the Classic how many boats w...</td>\n",
       "      <td>How does VanDam cope with the pressures and di...</td>\n",
       "      <td>VanDam copes with the pressures and distractio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9598</th>\n",
       "      <td>Ok, they aren't real interrupts... its actuall...</td>\n",
       "      <td>What does the program written by the author do?</td>\n",
       "      <td>The program written by the author locks the sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9599</th>\n",
       "      <td>Moonview Highway is a race track appearing in ...</td>\n",
       "      <td>What happens when a player with a Mega Mushroo...</td>\n",
       "      <td>Players who have the Mega Mushroom in effect m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0     Caption: Tasmanian berry grower Nic Hansen sho...   \n",
       "1     RWSN Collaborations\\nSouthern Africa Self-supp...   \n",
       "2     All Android applications categories\\nDescripti...   \n",
       "3     How unequal is India? The question is simple, ...   \n",
       "4     Gunnar Nelson took his time on the feet agains...   \n",
       "...                                                 ...   \n",
       "9595  For teenagers, getting their first car is a ri...   \n",
       "9596  I Sold the Farm (farm #1) for a client in cent...   \n",
       "9597  Entry 150, during the Classic how many boats w...   \n",
       "9598  Ok, they aren't real interrupts... its actuall...   \n",
       "9599  Moonview Highway is a race track appearing in ...   \n",
       "\n",
       "                                               question  \\\n",
       "0     What is the Berry Export Summary 2028 and what...   \n",
       "1     What are some of the benefits reported from ha...   \n",
       "2     What are the unique features of the Coolands f...   \n",
       "3     What is the main difference between the Nation...   \n",
       "4     How did Gunnar Nelson win the fight against Za...   \n",
       "...                                                 ...   \n",
       "9595  What are some ways to lower the cost of a teen...   \n",
       "9596  What was the unique action taken by the buyer ...   \n",
       "9597  How does VanDam cope with the pressures and di...   \n",
       "9598    What does the program written by the author do?   \n",
       "9599  What happens when a player with a Mega Mushroo...   \n",
       "\n",
       "                                                 answer  \n",
       "0     The Berry Export Summary 2028 is a dedicated e...  \n",
       "1     Benefits reported from having access to Self-s...  \n",
       "2     The unique features of the Coolands for Twitte...  \n",
       "3     The main difference between the NSS and the IH...  \n",
       "4     Gunnar Nelson won the fight against Zak Cummin...  \n",
       "...                                                 ...  \n",
       "9595  Some ways to lower the cost of a teenager's ca...  \n",
       "9596  The buyer took the brand new sign of the selle...  \n",
       "9597  VanDam copes with the pressures and distractio...  \n",
       "9598  The program written by the author locks the sh...  \n",
       "9599  Players who have the Mega Mushroom in effect m...  \n",
       "\n",
       "[9600 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b674ccdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\timur\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\timur\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\timur\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\timur\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\timur\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, multiprocess, datasets\n",
      "Successfully installed datasets-3.6.0 multiprocess-0.70.16 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8730cc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a622641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a knowledgeable and helpful chatbot designed to answer questions based on a specific text provided by the user. Your goal is to deliver accurate and concise answers by closely analyzing the content of the given text. \n",
    "Follow these guidelines to ensure high-quality responses:\n",
    "1. Careful Analysis:\n",
    "   - Thoroughly read and understand the given text before attempting to answer any questions.\n",
    "   - Identify key details, themes, and important points within the text.\n",
    "\n",
    "2. Relevant Responses:\n",
    "   - Provide answers that are directly relevant to the information contained in the text.\n",
    "   - Avoid using external knowledge or assumptions not supported by the text unless explicitly instructed to do so.\n",
    "\n",
    "3. Clarity and Precision:\n",
    "   - Ensure answers are clear, precise, and to the point.\n",
    "   - Use simple and direct language for better understanding.\n",
    "\n",
    "4. Text Quotation:\n",
    "   - When beneficial, quote directly from the text to support your answers. Ensure quoted material is relevant and clearly attributed.\n",
    "\n",
    "5. If Uncertain:\n",
    "   - If the text does not provide enough information to answer a question, politely inform the user that the answer cannot be determined from the text.\n",
    "\n",
    "6. Respectful Communication:\n",
    "   - Always communicate respectfully and politely, maintaining a helpful tone.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a3469ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstart=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6e43a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5437af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# answers = []\n",
    "# for message in tqdm(df.context.values):\n",
    "#     messages = [\n",
    "#     (\"system\",prompt),\n",
    "#     (\"human\",message)\n",
    "#            ]\n",
    "#     answer = llm.invoke(messages).content\n",
    "#     answers.append(answer)#eval(answer[answer.find(\"{\"):])['classification'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc165eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caption: Tasmanian berry grower Nic Hansen sho...</td>\n",
       "      <td>What is the Berry Export Summary 2028 and what...</td>\n",
       "      <td>The Berry Export Summary 2028 is a dedicated e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RWSN Collaborations\\nSouthern Africa Self-supp...</td>\n",
       "      <td>What are some of the benefits reported from ha...</td>\n",
       "      <td>Benefits reported from having access to Self-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All Android applications categories\\nDescripti...</td>\n",
       "      <td>What are the unique features of the Coolands f...</td>\n",
       "      <td>The unique features of the Coolands for Twitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How unequal is India? The question is simple, ...</td>\n",
       "      <td>What is the main difference between the Nation...</td>\n",
       "      <td>The main difference between the NSS and the IH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gunnar Nelson took his time on the feet agains...</td>\n",
       "      <td>How did Gunnar Nelson win the fight against Za...</td>\n",
       "      <td>Gunnar Nelson won the fight against Zak Cummin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Last Sunday, as part of a brunch with friends,...</td>\n",
       "      <td>What was the unanimous favourite chocolate bar...</td>\n",
       "      <td>The unanimous favourite was the Organic Cappuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Printable View\\nhow often does Orlando Hire?\\n...</td>\n",
       "      <td>What does the SAFER grant require Orlando to d...</td>\n",
       "      <td>The SAFER grant requires Orlando to replace an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>A recent survey of Canadian workers by pension...</td>\n",
       "      <td>What percentage of Canadian workers with a tra...</td>\n",
       "      <td>50 per cent of workers with a traditional defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>As soon as it hits October I start planning my...</td>\n",
       "      <td>What type of pears are recommended for making ...</td>\n",
       "      <td>Anjou pears, Bosc pears, and Bartlett pears ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>At some point a couple of weeks ago my blog tu...</td>\n",
       "      <td>Why did the author decide to leave Blogger for...</td>\n",
       "      <td>The author decided to leave Blogger because it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    Caption: Tasmanian berry grower Nic Hansen sho...   \n",
       "1    RWSN Collaborations\\nSouthern Africa Self-supp...   \n",
       "2    All Android applications categories\\nDescripti...   \n",
       "3    How unequal is India? The question is simple, ...   \n",
       "4    Gunnar Nelson took his time on the feet agains...   \n",
       "..                                                 ...   \n",
       "995  Last Sunday, as part of a brunch with friends,...   \n",
       "996  Printable View\\nhow often does Orlando Hire?\\n...   \n",
       "997  A recent survey of Canadian workers by pension...   \n",
       "998  As soon as it hits October I start planning my...   \n",
       "999  At some point a couple of weeks ago my blog tu...   \n",
       "\n",
       "                                              question  \\\n",
       "0    What is the Berry Export Summary 2028 and what...   \n",
       "1    What are some of the benefits reported from ha...   \n",
       "2    What are the unique features of the Coolands f...   \n",
       "3    What is the main difference between the Nation...   \n",
       "4    How did Gunnar Nelson win the fight against Za...   \n",
       "..                                                 ...   \n",
       "995  What was the unanimous favourite chocolate bar...   \n",
       "996  What does the SAFER grant require Orlando to d...   \n",
       "997  What percentage of Canadian workers with a tra...   \n",
       "998  What type of pears are recommended for making ...   \n",
       "999  Why did the author decide to leave Blogger for...   \n",
       "\n",
       "                                                answer  \n",
       "0    The Berry Export Summary 2028 is a dedicated e...  \n",
       "1    Benefits reported from having access to Self-s...  \n",
       "2    The unique features of the Coolands for Twitte...  \n",
       "3    The main difference between the NSS and the IH...  \n",
       "4    Gunnar Nelson won the fight against Zak Cummin...  \n",
       "..                                                 ...  \n",
       "995  The unanimous favourite was the Organic Cappuc...  \n",
       "996  The SAFER grant requires Orlando to replace an...  \n",
       "997  50 per cent of workers with a traditional defi...  \n",
       "998  Anjou pears, Bosc pears, and Bartlett pears ar...  \n",
       "999  The author decided to leave Blogger because it...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4682dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "import pandas as pd\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    #temperature=0.7,  \n",
    "    #request_timeout=30 \n",
    "    #\"Gemma3:12b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068cccf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab193c4b34140e9abdccf83a37162ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timur\\AppData\\Local\\Temp\\ipykernel_9564\\540472230.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answerllama8b']=results\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "results = []  \n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    system_message = (\n",
    "        f\"{prompt}\\n\"\n",
    "        f\"Context: {row['context']}\\n\"\n",
    "    )\n",
    "    messages = [\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", row[\"question\"])\n",
    "    ]\n",
    "    try:\n",
    "        answer = llm.invoke(messages).content\n",
    "        results.append(answer)\n",
    "    except: results.append('bad')\n",
    "df['answerllama8b']=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7beafa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timur\\AppData\\Local\\Temp\\ipykernel_9564\\2433511695.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answerllama8b']=results\n"
     ]
    }
   ],
   "source": [
    "df['answerllama8b']=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7e85e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600f3087a5b342b292ae01428611b490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timur\\AppData\\Local\\Temp\\ipykernel_9564\\3580261047.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answerllama3b']=results\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "import pandas as pd\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:3b\",\n",
    "    #temperature=0.7,  \n",
    "    #request_timeout=30 \n",
    "    #\"Gemma3:12b\"\n",
    ")\n",
    "results = []  \n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    system_message = (\n",
    "        f\"{prompt}\\n\"\n",
    "        f\"Context: {row['context']}\\n\"\n",
    "    )\n",
    "    messages = [\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", row[\"question\"])\n",
    "    ]\n",
    "    try:\n",
    "        answer = llm.invoke(messages).content\n",
    "        results.append(answer)\n",
    "    except: results.append('bad')\n",
    "df['answerllama3b']=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e537dbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925c71aa646546658daed198997073ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timur\\AppData\\Local\\Temp\\ipykernel_9564\\1570010814.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answerGemma3:12b']=results\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "import pandas as pd\n",
    "llm = ChatOllama(\n",
    "    model=\"Gemma3:12b\",\n",
    "    #temperature=0.7,  \n",
    "    #request_timeout=30 \n",
    "    #\"Gemma3:12b\"\n",
    ")\n",
    "results = []  \n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    system_message = (\n",
    "        f\"{prompt}\\n\"\n",
    "        f\"Context: {row['context']}\\n\"\n",
    "    )\n",
    "    messages = [\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", row[\"question\"])\n",
    "    ]\n",
    "    try:\n",
    "        answer = llm.invoke(messages).content\n",
    "        results.append(answer)\n",
    "    except: results.append('bad')\n",
    "df['answerGemma3:12b']=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0d91213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b7515",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df2[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ae22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "def sanitize_json_string(response_str: str) -> str:\n",
    "    response_str = response_str.strip()\n",
    "    if response_str.startswith(\"```\"):\n",
    "        response_str = re.sub(r\"^```(?:\\s*json\\s*)?\\n\", \"\", response_str)\n",
    "        response_str = re.sub(r\"\\n```$\", \"\", response_str)\n",
    "    return response_str\n",
    "llm2 = ChatOllama(\n",
    "    model=\"phi4\",  \n",
    "    temperature=0.0, \n",
    ")\n",
    "\n",
    "def evaluate_answers(context: str, question: str, reference_answer: str, llama_answer: str) -> Dict[str, int]:\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in evaluating the quality of AI-generated answers. Rate the model's response on a scale from 1 to 10 (1 = Poor, 10 = Excellent). Your evaluation must be extremely strict. Award a score of 10 only when the answer is flawless in every aspect.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Reference Answer: {reference_answer}\n",
    "Model's Answer: {llama_answer}\n",
    "\n",
    "### Evaluation Criteria\n",
    "1. Answer Correctness – How precisely the model’s answer matches the reference answer.\n",
    "2. Faithfulness – Whether the answer aligns accurately with the provided context.\n",
    "3. Answer Relevance – How directly the answer responds to the question.\n",
    "\n",
    "Make sure that:\n",
    "• A score of 10 is only reserved for answers that are completely ideal and without any error.\n",
    "• Scores below 10 reflect the presence of even minor imperfections or deviations.\n",
    "\n",
    "Return ONLY a JSON object without any explanation, using one of the following formats:\n",
    "{{\n",
    "  \"answer_correctness\": 8,\n",
    "  \"faithfulness\": 6,\n",
    "  \"answer_relevance\": 10\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an AI evaluation expert. Provide ONLY JSON output\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "    \n",
    "    response = llm2.invoke(messages)\n",
    "    response_str = sanitize_json_string(response.content)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(response_str)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Parsing error: {response.content}\")\n",
    "        return {\n",
    "            \"answer_correctness\": -1,\n",
    "            \"faithfulness\": -1,\n",
    "            \"answer_relevance\": -1\n",
    "        }\n",
    "results = []\n",
    "for _, row in df.iterrows():\n",
    "    eval_result = evaluate_answers(\n",
    "        context=row[\"context\"],\n",
    "        question=row[\"question\"],\n",
    "        reference_answer=row[\"answer\"],\n",
    "        llama_answer=row[\"answerllama3b\"]\n",
    "    )\n",
    "    results.append(eval_result)\n",
    "df_eval = pd.DataFrame(results)\n",
    "df_final = pd.concat([df, df_eval], axis=1)\n",
    "df_final.rename(columns={'answer_correctness': 'answer_correctness_llama3b'}, inplace=True)\n",
    "df_final.rename(columns={'faithfulness': 'faithfulness_llama3b'}, inplace=True)\n",
    "df_final.rename(columns={'answer_relevance': 'answer_relevance_llama3b'}, inplace=True)\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf12d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "def sanitize_json_string(response_str: str) -> str:\n",
    "    response_str = response_str.strip()\n",
    "    if response_str.startswith(\"```\"):\n",
    "        response_str = re.sub(r\"^```(?:\\s*json\\s*)?\\n\", \"\", response_str)\n",
    "        response_str = re.sub(r\"\\n```$\", \"\", response_str)\n",
    "    return response_str\n",
    "llm2 = ChatOllama(\n",
    "    model=\"phi4\",  \n",
    "    temperature=0.0, \n",
    ")\n",
    "\n",
    "def evaluate_answers(context: str, question: str, reference_answer: str, llama_answer: str) -> Dict[str, int]:\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in evaluating the quality of AI-generated answers. Rate the model's response on a scale from 1 to 10 (1 = Poor, 10 = Excellent). Your evaluation must be extremely strict. Award a score of 10 only when the answer is flawless in every aspect.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Reference Answer: {reference_answer}\n",
    "Model's Answer: {llama_answer}\n",
    "\n",
    "### Evaluation Criteria\n",
    "1. Answer Correctness – How precisely the model’s answer matches the reference answer.\n",
    "2. Faithfulness – Whether the answer aligns accurately with the provided context.\n",
    "3. Answer Relevance – How directly the answer responds to the question.\n",
    "\n",
    "Make sure that:\n",
    "• A score of 10 is only reserved for answers that are completely ideal and without any error.\n",
    "• Scores below 10 reflect the presence of even minor imperfections or deviations.\n",
    "\n",
    "Return ONLY a JSON object without any explanation, using one of the following formats:\n",
    "{{\n",
    "  \"answer_correctness\": 8,\n",
    "  \"faithfulness\": 6,\n",
    "  \"answer_relevance\": 10\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an AI evaluation expert. Provide ONLY JSON output\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "    \n",
    "    response = llm2.invoke(messages)\n",
    "    response_str = sanitize_json_string(response.content)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(response_str)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Parsing error: {response.content}\")\n",
    "        return {\n",
    "            \"answer_correctness\": -1,\n",
    "            \"faithfulness\": -1,\n",
    "            \"answer_relevance\": -1\n",
    "        }\n",
    "results = []\n",
    "for _, row in df.iterrows():\n",
    "    eval_result = evaluate_answers(\n",
    "        context=row[\"context\"],\n",
    "        question=row[\"question\"],\n",
    "        reference_answer=row[\"answer\"],\n",
    "        llama_answer=row[\"answerllama8b\"]\n",
    "    )\n",
    "    results.append(eval_result)\n",
    "df_eval = pd.DataFrame(results)\n",
    "df_final = pd.concat([df_final, df_eval], axis=1)\n",
    "df_final.rename(columns={'answer_correctness': 'answer_correctness_llama8b'}, inplace=True)\n",
    "df_final.rename(columns={'faithfulness': 'faithfulness_llama8b'}, inplace=True)\n",
    "df_final.rename(columns={'answer_relevance': 'answer_relevance_llama8b'}, inplace=True)\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "def sanitize_json_string(response_str: str) -> str:\n",
    "    response_str = response_str.strip()\n",
    "    if response_str.startswith(\"```\"):\n",
    "        response_str = re.sub(r\"^```(?:\\s*json\\s*)?\\n\", \"\", response_str)\n",
    "        response_str = re.sub(r\"\\n```$\", \"\", response_str)\n",
    "    return response_str\n",
    "llm2 = ChatOllama(\n",
    "    model=\"phi4\",  \n",
    "    temperature=0.0, \n",
    ")\n",
    "\n",
    "def evaluate_answers(context: str, question: str, reference_answer: str, llama_answer: str) -> Dict[str, int]:\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in evaluating the quality of AI-generated answers. Rate the model's response on a scale from 1 to 10 (1 = Poor, 10 = Excellent). Your evaluation must be extremely strict. Award a score of 10 only when the answer is flawless in every aspect.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Reference Answer: {reference_answer}\n",
    "Model's Answer: {llama_answer}\n",
    "\n",
    "### Evaluation Criteria\n",
    "1. Answer Correctness – How precisely the model’s answer matches the reference answer.\n",
    "2. Faithfulness – Whether the answer aligns accurately with the provided context.\n",
    "3. Answer Relevance – How directly the answer responds to the question.\n",
    "\n",
    "Make sure that:\n",
    "• A score of 10 is only reserved for answers that are completely ideal and without any error.\n",
    "• Scores below 10 reflect the presence of even minor imperfections or deviations.\n",
    "\n",
    "Return ONLY a JSON object without any explanation, using one of the following formats:\n",
    "{{\n",
    "  \"answer_correctness\": 8,\n",
    "  \"faithfulness\": 6,\n",
    "  \"answer_relevance\": 10\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an AI evaluation expert. Provide ONLY JSON output\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "    \n",
    "    response = llm2.invoke(messages)\n",
    "    response_str = sanitize_json_string(response.content)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(response_str)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Parsing error: {response.content}\")\n",
    "        return {\n",
    "            \"answer_correctness\": -1,\n",
    "            \"faithfulness\": -1,\n",
    "            \"answer_relevance\": -1\n",
    "        }\n",
    "results = []\n",
    "for _, row in df.iterrows():\n",
    "    eval_result = evaluate_answers(\n",
    "        context=row[\"context\"],\n",
    "        question=row[\"question\"],\n",
    "        reference_answer=row[\"answer\"],\n",
    "        llama_answer=row[\"answerGemma3:12b\"]\n",
    "    )\n",
    "    results.append(eval_result)\n",
    "df_eval = pd.DataFrame(results)\n",
    "df_final = pd.concat([df_final, df_eval], axis=1)\n",
    "df_final.rename(columns={'answer_correctness': 'answer_correctness_answerGemma3:12b'}, inplace=True)\n",
    "df_final.rename(columns={'faithfulness': 'faithfulness_answerGemma3:12b'}, inplace=True)\n",
    "df_final.rename(columns={'answer_relevance': 'answer_relevance_answerGemma3:12b'}, inplace=True)\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f19e73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=df_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67eea5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=df_result[df_result['answer_correctness_llama3b']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc7c7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=df_result[df_result['answer_correctness_llama8b']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "570e4368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=df_result[df_result['answerGemma3:12b']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "546c9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7427c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('df_rag_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166ebe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
