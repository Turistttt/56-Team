{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695a9250-ca87-435e-9eee-8c3141d11e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from fastembed import SparseTextEmbedding\n",
    "import pandas as pd\n",
    "from qdrant_client import QdrantClient, models\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class HybridBench():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dense_model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                 sparse_model_name = 'Qdrant/bm25',\n",
    "                 device=\"cpu\",\n",
    "                 load_batch_size = 32,\n",
    "                 m = 16,\n",
    "                 ef_construct = 100,\n",
    "                 full_scan_threshold = 10):\n",
    "        \"\"\"\n",
    "        Initializes the Bench class.\n",
    "\n",
    "        Args:\n",
    "            model_name (str): Name of the model for generating embeddings. Defaults to \"all-MiniLM-L6-v2\".\n",
    "            device (str): Device for computation. Defaults to \"cuda\".\n",
    "        \"\"\"\n",
    "        self.dense_model_name = dense_model_name\n",
    "        self.sparse_model_name = sparse_model_name\n",
    "\n",
    "        self.dense_model = SentenceTransformer(self.dense_model_name, device=device)\n",
    "        self.sparse_model = SparseTextEmbedding(self.sparse_model_name)\n",
    "        self.load_batch_size = load_batch_size\n",
    "\n",
    "        self.client = QdrantClient()\n",
    "        self.dataset = pd.read_parquet(\n",
    "            'hf://datasets/neural-bridge/rag-dataset-12000/data/train-00000-of-00001-9df3a936e1f63191.parquet'\n",
    "        ).dropna().reset_index(drop=True)\n",
    "        \n",
    "        self.m = m\n",
    "        self.full_scan_threshold = full_scan_threshold\n",
    "        self.ef_construct = ef_construct\n",
    "\n",
    "    def prepare_collection(self):\n",
    "        \"\"\"\n",
    "        Prepares the Qdrant collection based on the type of model (sparse or dense).\n",
    "        \"\"\"\n",
    "\n",
    "        if self.client.collection_exists(collection_name=\"test\"):\n",
    "            self.client.delete_collection(collection_name=\"test\")\n",
    "\n",
    "        self.client.create_collection(\n",
    "            collection_name=\"test\",\n",
    "            vectors_config={\n",
    "                self.dense_model_name: models.VectorParams(\n",
    "                    size=self.dense_model.get_sentence_embedding_dimension(), \n",
    "                    distance=models.Distance.COSINE\n",
    "                )\n",
    "            },  \n",
    "            sparse_vectors_config={\n",
    "                    self.sparse_model_name: models.SparseVectorParams(modifier=models.Modifier.IDF)\n",
    "                } if self.sparse_model_name == 'Qdrant/bm25' else None,\n",
    "        )\n",
    "\n",
    "\n",
    "        for i in tqdm(range(len(self.dataset)//32 + 1)):\n",
    "            row = self.dataset.iloc[i * self.load_batch_size : (1 + i) * self.load_batch_size]\n",
    "            \n",
    "            dense_embeddings = list(self.dense_model.encode(row[\"context\"].values))\n",
    "            bm25_embeddings = list(self.sparse_model.passage_embed(row[\"context\"].values))\n",
    "          \n",
    "            self.client.upload_points(\n",
    "                \"test\",\n",
    "                points=[\n",
    "                    models.PointStruct(\n",
    "                        id=int(id_),\n",
    "                        vector={\n",
    "                            self.dense_model_name: dense_embeddings[i],\n",
    "                            self.sparse_model_name: bm25_embeddings[i].as_object(),\n",
    "                        },\n",
    "                        payload={\n",
    "                            \"_id\": i,\n",
    "                            \"text\": row[\"context\"][id_],\n",
    "                        }\n",
    "                    ) for i, id_ in enumerate(self.dataset.iloc[i * self.load_batch_size : (i +1) * self.load_batch_size].index)\n",
    "                ],\n",
    "                batch_size=self.load_batch_size,\n",
    "            )\n",
    "    def score_collection(self):\n",
    "        \"\"\"\n",
    "        Evaluates the quality of the collection based on search results.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing evaluation metrics.\n",
    "        \"\"\"\n",
    "        dense_queries = list(self.dense_model.encode(self.dataset['question'], show_progress_bar=True,batch_size = self.load_batch_size))\n",
    "        sparse_queries = [vec for vec in self.sparse_model.embed(self.dataset['question'], show_progress_bar=True, batch_size=self.load_batch_size)]\n",
    "\n",
    "        \n",
    "        search_results = []\n",
    "        \n",
    "        for query_idx in tqdm(range(len(dense_queries))):\n",
    "            \n",
    "            dense_query_vector = dense_queries[query_idx]\n",
    "            sparse_query_vector = sparse_queries[query_idx]\n",
    "            \n",
    "            prefetch = [\n",
    "                models.Prefetch(\n",
    "                    query=dense_query_vector,\n",
    "                    using=self.dense_model_name,\n",
    "                    limit=100,\n",
    "                ),\n",
    "                models.Prefetch(\n",
    "                    query=models.SparseVector(**sparse_query_vector.as_object()),\n",
    "                    using=self.sparse_model_name,\n",
    "                    limit=100,\n",
    "                ),\n",
    "            ]\n",
    "            \n",
    "            results = self.client.query_points(\n",
    "                \"test\",\n",
    "                prefetch=prefetch,\n",
    "                query=models.FusionQuery(\n",
    "                    fusion=models.Fusion.RRF,\n",
    "                ),\n",
    "                with_payload=False,\n",
    "                limit = 100\n",
    "                # query=late_query_vector,\n",
    "                # using=\"colbertv2.0\",\n",
    "                # with_payload=False,\n",
    "                # limit=10,\n",
    "            ).points  \n",
    "        \n",
    "        \n",
    "            search_results.append(results)\n",
    "        ids = [list(map(lambda x: x.id, result)) for result in search_results]\n",
    "\n",
    "        biases = []\n",
    "        for vector in range(len(ids)):\n",
    "            if vector in ids[vector]:\n",
    "                bias = ids[vector].index(vector)\n",
    "                biases.append(bias)\n",
    "            else:\n",
    "                biases.append(101)\n",
    "        \n",
    "        metrics_dict = {\n",
    "            'recall@10': np.mean(np.array(biases) <= 10),\n",
    "            'recall@20': np.mean(np.array(biases) <= 20),\n",
    "            'recall@30': np.mean(np.array(biases) <= 30),\n",
    "            'recall@50': np.mean(np.array(biases) <= 50),\n",
    "            'recall@100': np.mean(np.array(biases) <= 100)\n",
    "        }\n",
    "        metric_df = pd.DataFrame([metrics_dict])\n",
    "        metric_df.index = [self.dense_model_name.split(\"/\")[-1] + \"_\" + self.sparse_model_name.split(\"/\")[-1]]\n",
    "        metric_df.to_csv(f\"{metric_df.index[0]}_result.csv\")\n",
    "        return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d66625f4-b170-4507-8fd3-d990c2c0f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = HybridBench(device = 'mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c344a57-0042-4553-b78f-64baae9143f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965ecfe3ed8949268858f6bf6e7ea355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.prepare_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64ff1fc2-dca2-4641-bf37-b377a0030fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e54768805af4df59b38e80ba67e3a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120379eb39584780934b5966713191f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9598 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall@10</th>\n",
       "      <th>recall@20</th>\n",
       "      <th>recall@30</th>\n",
       "      <th>recall@50</th>\n",
       "      <th>recall@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all-MiniLM-L6-v2_bm25</th>\n",
       "      <td>0.963117</td>\n",
       "      <td>0.970098</td>\n",
       "      <td>0.973953</td>\n",
       "      <td>0.978433</td>\n",
       "      <td>0.983851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       recall@10  recall@20  recall@30  recall@50  recall@100\n",
       "all-MiniLM-L6-v2_bm25   0.963117   0.970098   0.973953   0.978433    0.983851"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.score_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf31e0c-7ca8-4bf8-8cfe-b8cb7f1b2a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f75282c28e34c3d95255db40ea72603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eeee6836c834ffa921251b5bab2281f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad854b7fe9234cd5803662cac4e2e26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491da452c80d41649dd3179dd767c19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f523d6c688949699cdcf572e8eb43f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b18e719ea524a518bfbe51c79d29f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bea34fcaf9640798b7af465906ddfb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a008c174ee1647cb80ce1deb823a46b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9598 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dense_model in [#\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                    # 'intfloat/multilingual-e5-small',\n",
    "                    # 'sentence-transformers/distiluse-base-multilingual-cased-v2',\n",
    "                    'sentence-transformers/all-mpnet-base-v2']:\n",
    "    \n",
    "    bench = HybridBench(dense_model_name = dense_model, device=\"mps\",)\n",
    "    bench.prepare_collection()\n",
    "    bench.score_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b597c8-18f2-46f6-a9de-16236b0ecba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
